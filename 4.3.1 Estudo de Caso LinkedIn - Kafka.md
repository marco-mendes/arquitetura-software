# Estudo de Caso: A Jornada de Escalabilidade do LinkedIn com Apache Kafka - Resumo

## Objetivo

Este estudo apresenta um resumo estruturado do artigo "The Scaling Journey of LinkedIn" publicado no ByteByteGo.

## 1. LinkedIn: Uma Visão Geral

O LinkedIn atende quase um bilhão de membros. A escalabilidade de sua infraestrutura foi essencial para manter uma experiência responsiva e confiável. O crescimento exigiu reformulações arquiteturais profundas, culminando na criação e uso extensivo do Apache Kafka.

## 2. A Arquitetura Monolítica Inicial (Leo)

Inicialmente, o LinkedIn utilizava um monolito chamado **Leo**, que tratava renderização, lógica de negócio e persistência. Esse modelo centralizado rapidamente se mostrou limitado conforme as funcionalidades e a base de usuários aumentavam.

## 3. Especialização de Componentes: Gráfico de Conexão e Busca

Para superar as limitações do monolito, o LinkedIn passou a especializar componentes:

* Criou o **serviço de grafo de conexão (Cloud)**, particionado, distribuído e replicado para representar relações sociais entre membros.
* Desenvolveu o **serviço de busca**, responsável pela indexação eficiente e respostas rápidas.

Esses serviços eram acessados via chamadas remotas, reduzindo a dependência do Leo.

## 4. Arquitetura Orientada a Serviços (SOA)

A seguir, o LinkedIn migrou para uma arquitetura com vários serviços interligados. Embora isso permitisse divisão de responsabilidades e paralelismo, surgiram problemas com chamadas RPC em cascata:

* Acoplamento elevado;
* Latência imprevisível;
* Dificuldade de coordenação entre serviços dependentes.

## 5. Apache Kafka: Solução para Desacoplamento

Para resolver esses problemas, foi criado o **Apache Kafka**, permitindo desacoplamento total entre componentes.

Apache Kafka é um armazenamento de dados distribuído otimizado para ingestão e processamento de dados de streaming em tempo real. Dados de transmissão são dados gerados continuamente por milhares de fontes de dados, que normalmente enviam os registros de dados simultaneamente. Uma plataforma de transmissão precisa lidar com esse fluxo constante de dados e processá-los de forma sequencial e incremental.

O Kafka fornece três funções principais para seus usuários:

- Publicar e assinar fluxos de registros
- Armazenar fluxos de registros de forma eficaz na ordem em que os registros foram gerados
- Processar fluxos de registros em tempo real

O Kafka é usado para criar pipelines de dados de streaming em tempo real e aplicações de streaming em tempo real. Um pipeline de dados processa e move dados de um sistema para outro de forma confiável, e uma aplicação de streaming é uma aplicação que consome fluxos de dados. 

Por exemplo, se você quiser criar um pipeline de dados que receba dados de atividades do usuário para monitorar como as pessoas usam seu site em tempo real, o Kafka seria usado para ingerir e armazenar dados de streaming enquanto fornece leituras para os aplicações que alimentam o pipeline de dados. O Kafka também é frequentemente usado como uma solução de agente de mensagens, que é uma plataforma que processa e medeia a comunicação entre duas aplicações.


O Kafka atua como um backbone de comunicação entre serviços:

* Os **produtores** publicam eventos em tópicos;
* Os **consumidores** leem e processam os eventos de forma assíncrona;
* A **retenção** permite reprocessamento e auditabilidade;
* Os **dados são replicados** entre brokers para tolerância a falhas.
 

## 6. Arquitetura em Camadas com Kafka

Para lidar com o crescimento massivo de dados, o LinkedIn implementou uma topologia de Kafka em duas camadas:

* **Clusters locais**: recebem eventos produzidos em cada datacenter;
* **Clusters agregadores**: reprocessam e disponibilizam os dados de forma consolidada.

Isso reduziu custos com banda entre data centers e otimizou a entrega de eventos.

## 7. Escala Atual

Atualmente, a infraestrutura do LinkedIn com Kafka é composta por:

* Mais de 100 clusters Kafka;
* Cerca de 4.000 brokers;
* Mais de 7 trilhões de mensagens processadas por dia.

## 8. Ferramentas de Monitoramento e Governança

O LinkedIn desenvolveu diversas ferramentas para operar o Kafka em escala:

* **Kafka Audit**: garante que cada mensagem produzida foi corretamente entregue;
* **Cruise Control**: balanceia automaticamente partições entre brokers;
* **Monitoramento de lags**, topologias e disponibilidade.


## Referências
- ByteByteGo. (2024, May 28). The scaling journey of LinkedIn. ByteByteGo Newsletter. Retrieved from https://blog.bytebytego.com/p/the-scaling-journey-of-linkedin
- LinkedIn Engineering. (n.d.). A brief history of scaling LinkedIn. LinkedIn Engineering Blog. Retrieved from https://engineering.linkedin.com/architecture/brief-history-scaling-linkedin
- LinkedIn Engineering. (n.d.). Kafka at LinkedIn: Current and future. LinkedIn Engineering Blog. Retrieved from https://engineering.linkedin.com/kafka/kafka-linkedin-current-and-future

## Questões de Fixação

1. Qual era o nome do monólito original do LinkedIn e quais responsabilidades ele acumulava?

2. Quais foram os dois primeiros componentes que o LinkedIn especializou fora do monólito?

3. Quais problemas surgiram com o uso intensivo de chamadas RPC entre serviços no modelo SOA?

4. Como o Apache Kafka contribuiu para o desacoplamento entre produtores e consumidores de eventos no LinkedIn?

5. Descreva a arquitetura em camadas do Kafka usada pelo LinkedIn e sua motivação.

6. Quais mecanismos de governança e monitoramento foram implementados para manter a confiabilidade do Kafka em larga escala no LinkedIn?

7. Explique os seguintes conceitos centrais da arquitetura do Apache Kafka e sua relevância para sistemas distribuídos:- Tópico
- Producer
- Consumer
- Topic
- Partition
- Broker

